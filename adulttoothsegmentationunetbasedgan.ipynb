{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnCUHex5FZHY"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqxNfAj0FZo7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baD6VxrEFcGW"
      },
      "outputs": [],
      "source": [
        "dataset = 'https://www.kaggle.com/datasets/truthisneverlinear/childrens-dental-panoramic-radiographs-dataset'\n",
        "od.download(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joHOz5ixXbae"
      },
      "outputs": [],
      "source": [
        "!pip install natsort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqhLet8LDFkq"
      },
      "source": [
        "- Dental segmentation for adults. Many dentists suffer from the difficulty of analyzing panoramic images of teeth for adults. One of the difficulties that dentists suffer from is the difficulty in determining the extension and root of the teeth, which affects the decisions of doctors in many cases that include dental implants, tooth extraction, or other problems. Cases experienced by dentists are difficult.\n",
        "- In this study, it is proposed to use generative neuronal models in order to study more deeply the fragmentation process of teeth.\n",
        "- The use of generative networks helps to understand more deeply the shape in which the teeth can be formed, which helps in generalizing on the ability to segment the process, and this leads to models that are more understanding of the morphological structure of the teeth.\n",
        "- A generative neural network was proposed with the aim of segmenting the dental region of adults, and after completing the process of training the generative network, the generator was retrained only according to the concept of **pixel2pixel** and freezing the weights of a number of layers, in order to make the generator network depend on the training it received from the generative neural network.\n",
        "- The generative neural network achieved high results in the process of segmentation and tooth recognition, and those results were improved by retraining the generator with freezing a number of layers in order to make the generator able to generalize the results that were reached.\n",
        "- I was able to reach a stable training process free from overfitting and other problems that could face the training process.\n",
        "- The number of samples included in the dataset is small, so generative neural networks were used to build a segmentation model that is more generalizable. Within the same panoramic medical images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMtoJ5WcDFku"
      },
      "source": [
        "# IMPORT PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHwanagFXbag"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras import layers, models\n",
        "import pathlib\n",
        "import natsort\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhWTi6rZxeXW"
      },
      "outputs": [],
      "source": [
        "epochs = 10000\n",
        "batch = 16\n",
        "eta = 0.001\n",
        "weight_decay = 6e-8\n",
        "imageShape = (224, 224, 1)\n",
        "maskShape = (224, 224, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfYBMWE3DFkv"
      },
      "source": [
        "# READ DATASET (IMAGES, MASKS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9rbB3bdxeXX"
      },
      "outputs": [],
      "source": [
        "class readDataset:\n",
        "    def __init__(self, imagesPathes, masksPathes):\n",
        "        self.imagesPathes = imagesPathes\n",
        "        self.masksPathes = masksPathes\n",
        "    def readPathes(self,):\n",
        "      self.images = natsort.natsorted(list(pathlib.Path(self.imagesPathes).glob('*.*')))\n",
        "      self.masks = natsort.natsorted(list(pathlib.Path(self.masksPathes).glob('*.*')))\n",
        "    def readImages(self, data, typeData):\n",
        "        images = []\n",
        "        for img in data:\n",
        "            img = cv2.imread(str(img), 0)\n",
        "            img = img/255\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            if typeData == 'm':\n",
        "                img = np.where(img > 0, 1, 0)\n",
        "            images.append(img)\n",
        "        return np.array(images)\n",
        "    def dataAugmentation(self, images, masks):\n",
        "        imagesupdate = []\n",
        "        masksupdate = []\n",
        "        for image, mask in zip(images, masks):\n",
        "          for aug in range(2):\n",
        "            imageup = image\n",
        "            maskup = mask\n",
        "            if aug == 0:\n",
        "              imageup = image\n",
        "              maskup = mask\n",
        "            else:\n",
        "              imageup = tf.image.flip_left_right(imageup)\n",
        "              maskup = tf.image.flip_left_right(maskup)\n",
        "            imagesupdate.append(imageup), masksupdate.append(maskup)\n",
        "        return np.array(imagesupdate), np.array(masksupdate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3UQmNwvnnIm"
      },
      "outputs": [],
      "source": [
        "datasetObject = readDataset('./childrens-dental-panoramic-radiographs-dataset/Dental_dataset/Adult tooth segmentation dataset/Panoramic radiography database/images',\n",
        "                            './childrens-dental-panoramic-radiographs-dataset/Dental_dataset/Adult tooth segmentation dataset/Panoramic radiography database/mask')\n",
        "datasetObject.readPathes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQS24ueH_cyq"
      },
      "outputs": [],
      "source": [
        "len(datasetObject.images), len(datasetObject.masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKylNUS1xeXY"
      },
      "outputs": [],
      "source": [
        "images = datasetObject.readImages(datasetObject.images, 'i')\n",
        "masks = datasetObject.readImages(datasetObject.masks, 'm')\n",
        "images.shape, masks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LFivzgpnnIo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12, 12))\n",
        "for i in range(36):\n",
        "    plt.subplot(6, 6, (i + 1))\n",
        "    plt.imshow(images[i], cmap = 'gray')\n",
        "    plt.imshow(masks[i], alpha = 0.6, cmap = 'gray')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jtV4nBCpzrC"
      },
      "outputs": [],
      "source": [
        "np.unique(masks), np.min(masks), np.max(masks), np.min(images), np.max(masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSp86-7hDFky"
      },
      "source": [
        "# An example explaining the proposed methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3xtLNpLDFky"
      },
      "source": [
        "An example to understand the study of the shape of the tooth:\n",
        "Since I want to move away from the concept of studying pixel2pixel, and I want to study the morphological structure of the teeth and force the neural network to understand more deeply, the structure of the discriminant within the generative neural network includes, in the first layer, the process of applying the mask to the medical image and extracting the dental region only, and thus the discriminant will be studied in This case is the structure and shape of the teeth and their presence close to each other, regardless of the rest of the parts, medical images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRJwG7raDFkz"
      },
      "outputs": [],
      "source": [
        "x = layers.Input(shape = (224, 224, 1))\n",
        "y = layers.Input(shape = (224, 224, 1))\n",
        "z = layers.multiply([x, y])\n",
        "m = models.Model(inputs = [x, y], outputs = z)\n",
        "m.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgTiOwBhDFkz"
      },
      "outputs": [],
      "source": [
        "imagesByMasks = m([images[:64], masks[:64]])\n",
        "imagesByMasks.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk9qO06DDFkz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12, 12))\n",
        "for i in range(64):\n",
        "    plt.subplot(8, 8, (i + 1))\n",
        "    plt.imshow(imagesByMasks[i], cmap = 'gray')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8vNhxaVZ23R"
      },
      "outputs": [],
      "source": [
        "i = 80\n",
        "validImages = images[:i]\n",
        "validMasks = masks[:i]\n",
        "trainImages = images[i:]\n",
        "trainMasks = masks[i:]\n",
        "validImages.shape, validMasks.shape, trainImages.shape, trainMasks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUKelDtwDFkz"
      },
      "source": [
        "# Proposing a generative neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcAH125ap8MD"
      },
      "outputs": [],
      "source": [
        "def convolution(inputs, filter, padding, strides, kernel, activation, conv_type):\n",
        "  x = inputs\n",
        "  x = layers.Conv2D(filter, kernel_size = kernel, padding = padding,\n",
        "                    strides = strides)(x)\n",
        "  x = layers.GroupNormalization(groups = filter)(x)\n",
        "  if conv_type == 'decoder':\n",
        "      x = layers.Activation(activation)(x)\n",
        "      x = layers.Conv2D(filter*2, kernel_size = kernel, padding = padding, strides = strides)(x)\n",
        "      x = layers.GroupNormalization(groups = filter*2)(x)\n",
        "      x = layers.Activation(activation)(x)\n",
        "      x = layers.Conv2D(filter, kernel_size = kernel, padding = padding, strides = strides)(x)\n",
        "      x = layers.GroupNormalization(groups = filter)(x)\n",
        "  x = layers.average([x, layers.Conv2D(filter, kernel_size = 1, padding = 'same',\n",
        "                                      strides = 1)(inputs)])\n",
        "  x = layers.Activation(activation)(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6t7y6YxqAc6"
      },
      "outputs": [],
      "source": [
        "def encoder(input, filter, padding, strides, kernel, activation):\n",
        "  x = input\n",
        "  x = convolution(x, filter, padding, strides, kernel, activation, 'encoder')\n",
        "  downsample = layers.AveragePooling2D()(x)\n",
        "  return downsample, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3l_YejcqDaj"
      },
      "outputs": [],
      "source": [
        "def decoder(input, filter, skip, padding, strides, kernel, activation):\n",
        "  x = input\n",
        "  x = layers.Conv2DTranspose(filter, kernel_size = kernel, padding = padding,\n",
        "                             strides = 2, activation = activation)(x)\n",
        "  x = layers.average([x, skip])\n",
        "  x = convolution(x, filter, padding, strides, kernel, activation, 'decoder')\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-01v1Ig_npR"
      },
      "outputs": [],
      "source": [
        "def generator(input, filter, padding, strides, kernel, weights):\n",
        "  x = input\n",
        "  con1, skip1 = encoder(x, filter, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con2, skip2 = encoder(con1, filter*2, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con3, skip3 = encoder(con2, filter*4, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con4, skip4 = encoder(con3, filter*8, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con5, skip5 = encoder(con4, filter*16, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  deco = decoder(con5, filter*16, skip5, padding = padding, strides = strides,\n",
        "                  kernel = kernel, activation = 'relu')\n",
        "  deco1 = decoder(deco, filter*8, skip4, padding = padding, strides = strides,\n",
        "                  kernel = kernel, activation = 'relu')\n",
        "  deco2 = decoder(deco1, filter*4, skip3, padding = padding, strides = strides,\n",
        "                  kernel = kernel, activation = 'relu')\n",
        "  deco3 = decoder(deco2, filter*2, skip2, padding = padding, strides = strides,\n",
        "                  kernel = kernel, activation = 'relu')\n",
        "  deco4 = decoder(deco3, filter, skip1, padding = padding, strides = strides,\n",
        "                  kernel = kernel, activation = 'relu')\n",
        "  output = layers.Conv2DTranspose(1, kernel_size = kernel, strides = strides,\n",
        "                                  padding = padding, activation = 'sigmoid')(deco4)\n",
        "  generator = models.Model(inputs = input, outputs = output, name = 'generator')\n",
        "  if weights != None:\n",
        "    generator.load_weights('/kaggle/working/mask_generator.h5')\n",
        "  generator.summary()\n",
        "  return generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfaTJ8qcAthx"
      },
      "outputs": [],
      "source": [
        "G = generator(input = layers.Input(shape = (224, 224, 1)), filter = 32,\n",
        "              padding = 'same', kernel = 3, strides = 1, weights = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WxP95yNODFk0"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(G, show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VqVGN_BRBEF5"
      },
      "outputs": [],
      "source": [
        "def discriminator(ImageInput, maskInput, filter, padding, strides, kernel, weights,\n",
        "                  lossFn, learning_rate, weight_decay):\n",
        "  x = layers.multiply([ImageInput, maskInput])\n",
        "  con1, skip1 = encoder(x, filter, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con2, skip2 = encoder(con1, filter*2, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con3, skip3 = encoder(con2, filter*4, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con4, skip4 = encoder(con3, filter*8, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  con5, skip5 = encoder(con4, filter*16, padding = padding, strides = strides,\n",
        "                        kernel = kernel, activation = 'LeakyReLU')\n",
        "  x = layers.GlobalAveragePooling2D()(con5)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(1)(x)\n",
        "  discriminator = models.Model(inputs = [maskInput, ImageInput], outputs = x,\n",
        "                              name = 'discriminator')\n",
        "  if weights != None:\n",
        "    discriminator.load_weights('/kaggle/working/discriminator.h5')\n",
        "  discriminator.compile(loss = lossFn, optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate,\n",
        "                                                                              weight_decay = weight_decay))\n",
        "  discriminator.summary()\n",
        "  return discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "an1Idi66CkV4"
      },
      "outputs": [],
      "source": [
        "D = discriminator(ImageInput = layers.Input(shape = imageShape), maskInput = layers.Input(shape = maskShape),\n",
        "                  filter = 32, padding = 'same', strides = 1, kernel = 3, weights = None,\n",
        "                  lossFn = 'mse', learning_rate = eta, weight_decay = weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aFb-6rXOGWOQ"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(D, show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qSLaj3Ovqb9C"
      },
      "outputs": [],
      "source": [
        "def GAN(discriminator, generator, imageInput, maskInput, learning_rate, weight_decay,\n",
        "                   lossFn):\n",
        "  discriminator.trainable = False\n",
        "  gan = models.Model(\n",
        "      inputs = [imageInput],\n",
        "      outputs = discriminator([generator(imageInput), imageInput],),\n",
        "      name = 'gan'\n",
        "  )\n",
        "  gan.compile(loss = lossFn, optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate*0.5,\n",
        "                                                                              weight_decay = weight_decay*0.5))\n",
        "  gan.summary()\n",
        "  return gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AmAnNhVOEPGw"
      },
      "outputs": [],
      "source": [
        "gan = GAN(discriminator = D, generator = G, imageInput = layers.Input(shape = imageShape),\n",
        "          maskInput = layers.Input(shape = maskShape), learning_rate = eta, weight_decay = weight_decay,\n",
        "                   lossFn = 'mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MxIt_xn0FcX3"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(gan, show_shapes = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dBRZ5bekqhNi"
      },
      "outputs": [],
      "source": [
        "def samples(generator, images, realMasks):\n",
        "  masks = tf.squeeze(generator.predict(images))\n",
        "  all = np.vstack([realMasks, masks])\n",
        "  plt.figure(figsize = (12, 4))\n",
        "  for i in range(16):\n",
        "    plt.subplot(2, 8, (i + 1))\n",
        "    plt.imshow(all[i], cmap = 'gray')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwcMIVSgDFk2"
      },
      "source": [
        "- In the beginning, the generative neural network will find it difficult to understand exactly what is required of it, but with time, the generative network will realize that it has to generate a mask so that if it is applied to the panoramic image, we will extract areas of the teeth with the same characteristics and specifications that the distinguished one studied.\n",
        "- The main idea is to make the hashing task not easy and requires awareness on the part of the generator of what it should generate, since I did not tell it exactly what it should generate, but rather I left it to him to realize what he should generate.\n",
        "- As I mentioned, with time the generator will understand the idea and therefore will work on generating the mask without being asked to do so openly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhXyfVgZqlS5"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    indexs = np.random.randint(0, len(trainImages), size = (batch, ))\n",
        "    realImages = trainImages[indexs]\n",
        "    realMasks = trainMasks[indexs]\n",
        "    realTag = tf.ones(shape = (batch, ))\n",
        "    fakeMasks = tf.squeeze(G.predict([realImages], verbose = 0))\n",
        "    fakeTag = tf.zeros(shape = (batch, ))\n",
        "    allMasks = np.vstack([realMasks, fakeMasks])\n",
        "    allTags = np.hstack([realTag, fakeTag])\n",
        "    allImages = np.vstack([realImages, realImages])\n",
        "    dlossTag = D.train_on_batch([allMasks, allImages], [allTags])\n",
        "    glossTag = gan.train_on_batch([realImages], [realTag,])\n",
        "    if epoch % 500 == 0:\n",
        "        print('Epoch/Epochs: {}/{}'.format(epoch, epochs))\n",
        "        print('discriminator loss: [tag: {},], generator loss: [tag: {},]'.format(dlossTag, glossTag))\n",
        "        validIndexs = np.random.randint(0, len(validImages), size = (8, ))\n",
        "        samples(G, validImages[validIndexs], validMasks[validIndexs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMMfbd5pDqpx"
      },
      "outputs": [],
      "source": [
        "G.save_weights('./working/mask_generator.h5')\n",
        "D.save_weights('./working/mask_discriminator.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDFyeyYXDFk3"
      },
      "source": [
        "- Now we will train the generator again with a number of layers frozen in order to maintain the capacity that the generator has gained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV-CfhtkiSXy"
      },
      "outputs": [],
      "source": [
        "G = generator(input = layers.Input(shape = (224, 224, 1)), filter = 32,\n",
        "              padding = 'same', kernel = 3, strides = 1, weights = True)\n",
        "for layer in G.layers[:20]:\n",
        "  layer.trainable = False\n",
        "G.compile(loss = tf.keras.losses.BinaryFocalCrossentropy(),\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001),\n",
        "                  metrics = ['accuracy', tf.keras.metrics.Precision(name = 'precision'),\n",
        "                             tf.keras.metrics.Recall(name = 'recall')])\n",
        "G.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQoh0WfJDFk3"
      },
      "source": [
        "# Evaluation of training performance using generative neural networks on both training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e0alGWwDFk3"
      },
      "outputs": [],
      "source": [
        "G.evaluate(validImages, validMasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkvYfw7bDFlD"
      },
      "outputs": [],
      "source": [
        "G.evaluate(trainImages, trainMasks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPd-luHbDFlD"
      },
      "source": [
        "# Re-training of the generator according to the pixel2pixel methodology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXU2wFydjICg"
      },
      "outputs": [],
      "source": [
        "history = G.fit(trainImages, trainMasks, epochs = 160, batch_size = 8,\n",
        "                        validation_data = (validImages, validMasks), callbacks = [\n",
        "                            tf.keras.callbacks.EarlyStopping(patience = 5, monitor = 'val_loss',\n",
        "                                                             mode = 'min',\n",
        "                                                             restore_best_weights = True)\n",
        "                        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KovwHgWLDFlE"
      },
      "source": [
        "# The results obtained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dYpz7WRZtkE"
      },
      "outputs": [],
      "source": [
        "metrics = ['loss','accuracy', 'precision']\n",
        "plt.figure(figsize = (12, 6))\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 2, (i + 1))\n",
        "    plt.plot(history.history['{}'.format(metrics[i])], label = '{}'.format(metrics[i]))\n",
        "    plt.plot(history.history['val_{}'.format(metrics[i])], label = 'val_{}'.format(metrics[i]))\n",
        "    plt.title('{}'.format(metrics[i]))\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIT2z44FDFlE"
      },
      "outputs": [],
      "source": [
        "G.evaluate(validImages, validMasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy9TCXbbitYb"
      },
      "outputs": [],
      "source": [
        "G.evaluate(trainImages, trainMasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIO6gnzVDFlE"
      },
      "outputs": [],
      "source": [
        "G.save('./working/final_tooth_mask_generation.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8S6vZNPDFlF"
      },
      "outputs": [],
      "source": [
        "G = tf.keras.models.load_model('./working/final_tooth_mask_generation.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cvl9117EZI4"
      },
      "outputs": [],
      "source": [
        "masks_pred = G.predict(validImages)\n",
        "masks_pred = (masks_pred >= 0.5).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1JxosF-EkN5"
      },
      "outputs": [],
      "source": [
        "masks_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXRZnNbgErgi"
      },
      "outputs": [],
      "source": [
        "def draw(images, masks, y_pred):\n",
        "  plt.figure(figsize = (12, 50))\n",
        "  index = -1\n",
        "  n = np.random.randint(y_pred.shape[0])\n",
        "  for i in range(120):\n",
        "    plt.subplot(20, 6, (i + 1))\n",
        "    if index == -1:\n",
        "      plt.imshow(images[n], cmap = 'gray')\n",
        "      plt.title('Image')\n",
        "      index = 0\n",
        "    elif index == 0:\n",
        "      plt.imshow(images[n], cmap = 'gray')\n",
        "      plt.imshow(masks[n], alpha = 0.6, cmap = 'gray')\n",
        "      plt.title('Original Mask')\n",
        "      index = 1\n",
        "    elif index == 1:\n",
        "      plt.imshow(images[n], cmap = 'gray')\n",
        "      plt.imshow(np.reshape(y_pred[n], (224, 224)), alpha = 0.6, cmap = 'gray')\n",
        "      plt.title('Predict Mask')\n",
        "      index = -1\n",
        "      n = np.random.randint(y_pred.shape[0])\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kdDVzKfFGhJ"
      },
      "outputs": [],
      "source": [
        "draw(validImages, validMasks, masks_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qilD1o1DFlG"
      },
      "outputs": [],
      "source": [
        "masks_pred = G.predict(trainImages)\n",
        "masks_pred = (masks_pred >= 0.5).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEuRn7BTDFlG"
      },
      "outputs": [],
      "source": [
        "masks_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGn2RAu6DFlG"
      },
      "outputs": [],
      "source": [
        "draw(trainImages, trainMasks, masks_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsV020xYDFlG"
      },
      "outputs": [],
      "source": [
        "draw(trainImages, trainMasks, masks_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}